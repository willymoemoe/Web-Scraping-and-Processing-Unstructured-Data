{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fba6f74-5cfb-4fc6-b8c9-c78011e61ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from cloudflare_bypass import CloudflareBypass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7835e2ab-b903-40dc-aa87-8451088eedbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Use CloudflareBypass to bypass anti-scraping techniques\n",
    "bypasser = CloudflareBypass()\n",
    "session = requests.Session()\n",
    "session.headers.update(bypasser.get_headers())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf33060-0ab9-4f6d-a67f-38c944007e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Use Selenium to simulate a web browser and navigate the website\n",
    "url = \"https://example.com/books\"\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b31c695-4568-43da-8233-68689f5844a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Find the pagination links and scrape each page\n",
    "book_data = []\n",
    "\n",
    "while True:\n",
    "    # Scrape the current page\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    for book_div in soup.find_all(\"div\", class_=\"book\"):\n",
    "        book_title = book_div.find(\"h2\", class_=\"title\").text.strip()\n",
    "        book_author = book_div.find(\"p\", class_=\"author\").text.strip()\n",
    "        book_price = book_div.find(\"p\", class_=\"price\").text.strip()\n",
    "        book_rating = book_div.find(\"p\", class_=\"rating\").text.strip()\n",
    "        book_data.append({\"Title\": book_title, \"Author\": book_author, \"Price\": book_price, \"Rating\": book_rating})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d058f46-00d3-4c45-b993-af3938917b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there's a next page\n",
    "    next_button = driver.find_element_by_xpath(\"//a[@class='next']\")\n",
    "    if not next_button.is_enabled():\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d103379-c198-4773-8595-20beb652cfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Navigate to the next page\n",
    "    next_button.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ad1ae8-c22f-4904-a3d1-e04069429962",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Wait for Cloudflare to clear the CAPTCHA\n",
    "    bypasser.wait_for_cloudflare(driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c63bf6a-b1de-4e7a-83f9-c66cd540d973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Save the data to a CSV file\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b7e9e2-3711-48b7-9efb-a6db6fc15a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(book_data)\n",
    "df.to_csv(\"book_data.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-2022.05-py39",
   "language": "python",
   "name": "conda-env-anaconda-2022.05-py39-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
